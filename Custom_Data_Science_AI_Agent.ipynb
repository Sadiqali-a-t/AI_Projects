{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873935e0-e669-4b84-9495-6cc53f62121f",
   "metadata": {},
   "source": [
    "# importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d416f1b-7a55-456f-bbf7-f2f760b65242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ba873-1ce9-4f51-876c-6e958c91a71d",
   "metadata": {},
   "source": [
    "# LangChain / OpenAI imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35c27dd1-5104-40ca-9f2c-be9617efff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: openai in c:\\users\\user\\anaconda3\\lib\\site-packages (1.99.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\user\\anaconda3\\lib\\site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (0.4.13)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain openai faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "395811a0-008a-47fa-81d5-7b1e5e4bc875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.74)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.13)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "075b4f3d-f5e5-45c6-9736-05e60742c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import Document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938f8538-2e67-4b26-b52c-206c21a2cd6e",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62851f65-deb6-4873-9484-8de471c18132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path, max_rows=20000):\n",
    "    \"\"\"Load CSV with a cap to avoid OOM on very large files.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    if len(df) > max_rows:\n",
    "        print(f\"Warning: CSV has {len(df)} rows — truncating to first {max_rows} rows.\")\n",
    "        df = df.head(max_rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "def row_to_text(row: pd.Series, id_col=None, max_chars=1000) -> str:\n",
    "    \"\"\"Convert a DataFrame row to a short text summary for embedding/retrieval.\"\"\"\n",
    "    parts = []\n",
    "    if id_col and id_col in row.index:\n",
    "        parts.append(f\"id: {row[id_col]}\")\n",
    "    for c, v in row.items():\n",
    "        parts.append(f\"{c}: {v}\")\n",
    "    text = \" | \".join(parts)\n",
    "    if len(text) > max_chars:\n",
    "        text = text[: max_chars - 3] + \"...\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def build_docs_from_df(df: pd.DataFrame, id_col=None):\n",
    "    docs = []\n",
    "    for idx, row in df.iterrows():\n",
    "        text = row_to_text(row, id_col=id_col)\n",
    "        docs.append(Document(page_content=text, metadata={\"row_index\": int(idx)}))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3f279-7fcf-45d6-912e-277ed5b8adef",
   "metadata": {},
   "source": [
    "# Main agent builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d10c1762-2350-4d47-b015-7f3514a7e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore_from_csv(csv_path, id_col=None, openai_api_key=None):\n",
    "    df = load_csv(csv_path)\n",
    "    docs = build_docs_from_df(df, id_col=id_col)\n",
    "\n",
    "    # Setup embeddings\n",
    "    if openai_api_key is None:\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key:\n",
    "        raise ValueError(\"OpenAI API key not provided. Set OPENAI_API_KEY in environment or .env file.\")\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "    # Build FAISS in-memory index\n",
    "    print(\"Creating vectorstore and embedding rows — this may take a few moments...\")\n",
    "    vs = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "    print(f\"Indexed {len(docs)} rows into FAISS vectorstore.\")\n",
    "    return vs, df\n",
    "\n",
    "\n",
    "def create_conversational_chain(vs, openai_api_key=None, temperature=0.2):\n",
    "    if openai_api_key is None:\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    llm = ChatOpenAI(temperature=temperature, openai_api_key=openai_api_key)\n",
    "    retriever = vs.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "    chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ce29d-8951-4540-ac53-aba23046bf36",
   "metadata": {},
   "source": [
    "# Utilities for quick table summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bf3706b-9b42-4d3d-bf74-0f6e3a80102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_table_summary(df: pd.DataFrame, max_cols=10) -> str:\n",
    "    \"\"\"Return a short textual summary of the table for the LLM context.\"\"\"\n",
    "    lines = []\n",
    "    lines.append(f\"Rows: {len(df)}\")\n",
    "    lines.append(\"Columns:\")\n",
    "    cols = df.columns.tolist()[:max_cols]\n",
    "    for c in cols:\n",
    "        lines.append(f\" - {c} (dtype={df[c].dtype})\")\n",
    "    if len(df.columns) > max_cols:\n",
    "        lines.append(f\" ... and {len(df.columns)-max_cols} more columns\")\n",
    "\n",
    "    # Add basic statistics for numeric columns\n",
    "    num = df.select_dtypes(include=[\"number\"]).describe().T\n",
    "    if not num.empty:\n",
    "        lines.append(\"Numeric column summary (mean, std, min, max):\")\n",
    "        for c in num.index[:5]:  # limit to first 5 numeric cols\n",
    "            r = num.loc[c]\n",
    "            lines.append(f\" - {c}: mean={r['mean']:.3f}, std={r['std']:.3f}, min={r['min']}, max={r['max']}\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8869cee7-5dc8-4f59-8ca9-0ca64ff711b8",
   "metadata": {},
   "source": [
    "# CLI / REPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62e80a30-8836-44d0-9d42-1045347745f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repl(chain, df, history_limit=10):\n",
    "    print(\"\\n=== AI Data Agent REPL ===\\nType 'exit' to quit, 'summary' for table summary, or ask questions about the data.\\n\")\n",
    "    chat_history = []\n",
    "    while True:\n",
    "        q = input(\"You: \")\n",
    "        if not q:\n",
    "            continue\n",
    "        q_stripped = q.strip().lower()\n",
    "        if q_stripped in (\"exit\", \"quit\"):\n",
    "            print(\"Goodbye — session ended.\")\n",
    "            break\n",
    "        if q_stripped == \"summary\":\n",
    "            print(quick_table_summary(df))\n",
    "            continue\n",
    "\n",
    "        # Ask the chain — it expects a dict with 'question' and optionally 'chat_history'\n",
    "        res = chain.run({\"question\": q, \"chat_history\": chat_history})\n",
    "        print(\"Agent:\", res)\n",
    "\n",
    "        # Update history (simple append)\n",
    "        chat_history.append((q, res))\n",
    "        if len(chat_history) > history_limit:\n",
    "            chat_history = chat_history[-history_limit:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b171e-8ef4-48dd-8ea4-3d67bd0afd53",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9e969ec-8952-4e79-86c5-67e71d2b7415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --csv CSV [--id_col ID_COL] [--no_embed]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --csv\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Run a small AI agent over a CSV file.\")\n",
    "    parser.add_argument(\"--csv\", required=True, help=\"Path to CSV file\")\n",
    "    parser.add_argument(\"--id_col\", required=False, help=\"Optional column name to treat as ID\")\n",
    "    parser.add_argument(\"--no_embed\", action=\"store_true\", help=\"Skip building embeddings (not recommended) — just show summary\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    load_dotenv()  # load .env if present\n",
    "\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"Warning: OPENAI_API_KEY not found in environment. Make sure to set it before running.\")\n",
    "\n",
    "    if args.no_embed:\n",
    "        df = load_csv(args.csv)\n",
    "        print(quick_table_summary(df))\n",
    "        return\n",
    "\n",
    "    vs, df = create_vectorstore_from_csv(args.csv, id_col=args.id_col, openai_api_key=api_key)\n",
    "    chain = create_conversational_chain(vs, openai_api_key=api_key)\n",
    "    repl(chain, df)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3d506fa-e533-452d-879d-30fd9d259924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.10.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Downloading tiktoken-0.10.0-cp312-cp312-win_amd64.whl (875 kB)\n",
      "   ---------------------------------------- 0.0/875.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/875.7 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/875.7 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 875.7/875.7 kB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f59d37d-1df7-4a0a-afe5-932737f890aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('marketing_campaign.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78184714-0a13-4bd4-bf79-f4d160089fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for idx, row in df.iterrows():\n",
    "    text = \" | \".join([f\"{col}: {val}\" for col, val in row.items()])\n",
    "    docs.append(Document(page_content=text, metadata={\"row_index\": idx}))\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=\"api_key_here\")\n",
    "\n",
    "# Create vectorstore\n",
    "vs = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Create conversational chain\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatOpenAI(temperature=0, openai_api_key=\"api_key_here\"),\n",
    "    retriever=vs.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4cf7e3-979b-4f8a-9522-8118f2cfba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "question = \"Which marketing channel had the highest ROI?\"\n",
    "answer = chain.run({\"question\": question, \"chat_history\": chat_history})\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
